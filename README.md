# Image Captioning Tool

This project focuses on developing a system that automatically generates descriptive captions for images. This project utilizes both **CNN** and **RNN** to extract visual features and convert them into meaningful text descriptions.

### CNN
Pre-trained models like **VGG16** and **ResNet50** are used to extract relevant features from images.

### RNN
The project integrates **LSTM** (Long Short-Term Memory Networks), a form of RNN, to generate a sequence of words based on extracted image features.

### NLP
Various **NLP techniques** are used for tokenization, padding, and sequence generation to transform captions into a machine-understandable format.





